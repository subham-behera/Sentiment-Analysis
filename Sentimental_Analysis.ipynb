{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Import necessery libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxeYgQpJjzq6",
        "outputId": "60b612ae-2755-4a22-d362-c1091665f5eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('./train.csv')"
      ],
      "metadata": {
        "id": "wFMuJO35j41C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2K_tmPmXd811"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.strip()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['clean_text'] = df['selected_text'].fillna('No text').apply(preprocess_text)\n",
        "\n",
        "# Tokenization and Padding\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['clean_text'])\n",
        "sequences = tokenizer.texts_to_sequences(df['clean_text'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')\n",
        "\n",
        "# Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
        "y = df['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gcWczGCTkBVw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
        "\n",
        "# Build the RNN/LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=64, input_length=100))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcBBwgkWeKqU",
        "outputId": "59cf1c10-b66b-4761-a0bc-ff8825f01414"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 64)           640000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 100, 128)          66048     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100, 128)          0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 64)                41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 747459 (2.85 MB)\n",
            "Trainable params: 747459 (2.85 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQq__N2reO6i",
        "outputId": "faa450a6-8700-471b-dd42-9912dc54cbcf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "687/687 [==============================] - 33s 38ms/step - loss: 0.6752 - accuracy: 0.7216 - val_loss: 0.5014 - val_accuracy: 0.8115\n",
            "Epoch 2/10\n",
            "687/687 [==============================] - 15s 22ms/step - loss: 0.4540 - accuracy: 0.8426 - val_loss: 0.4941 - val_accuracy: 0.8179\n",
            "Epoch 3/10\n",
            "687/687 [==============================] - 15s 21ms/step - loss: 0.3601 - accuracy: 0.8787 - val_loss: 0.5218 - val_accuracy: 0.8155\n",
            "Epoch 4/10\n",
            "687/687 [==============================] - 15s 21ms/step - loss: 0.3081 - accuracy: 0.8984 - val_loss: 0.5457 - val_accuracy: 0.8083\n",
            "Epoch 5/10\n",
            "687/687 [==============================] - 14s 21ms/step - loss: 0.2721 - accuracy: 0.9106 - val_loss: 0.5875 - val_accuracy: 0.7983\n",
            "Epoch 6/10\n",
            "687/687 [==============================] - 15s 22ms/step - loss: 0.2494 - accuracy: 0.9201 - val_loss: 0.6386 - val_accuracy: 0.8017\n",
            "Epoch 7/10\n",
            "687/687 [==============================] - 14s 21ms/step - loss: 0.2287 - accuracy: 0.9262 - val_loss: 0.6828 - val_accuracy: 0.8061\n",
            "Epoch 8/10\n",
            "687/687 [==============================] - 15s 21ms/step - loss: 0.2106 - accuracy: 0.9307 - val_loss: 0.7266 - val_accuracy: 0.8033\n",
            "Epoch 9/10\n",
            "687/687 [==============================] - 16s 23ms/step - loss: 0.1993 - accuracy: 0.9335 - val_loss: 0.8307 - val_accuracy: 0.7873\n",
            "Epoch 10/10\n",
            "687/687 [==============================] - 14s 21ms/step - loss: 0.1855 - accuracy: 0.9369 - val_loss: 0.8150 - val_accuracy: 0.7992\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.8150 - accuracy: 0.7992\n",
            "Accuracy: 0.7991631627082825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('sentiment_model.h5')\n",
        "\n",
        "# Save the tokenizer\n",
        "import joblib\n",
        "joblib.dump(tokenizer, 'tokenizer.pkl')\n",
        "\n",
        "# Save the label encoder\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbhlUgT9eSLu",
        "outputId": "2667d25c-1d30-48ee-9e36-b1c9cdf755af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}